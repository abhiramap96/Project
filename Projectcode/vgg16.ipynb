{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ClJjVc3av9c",
        "outputId": "c9eb940c-8a1c-4838-dcad-50990f8f39da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_415Ce9a_Bl"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylWib95EbQ1E"
      },
      "outputs": [],
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/train_dir'\n",
        "valid_path = '/content/drive/MyDrive/val_dir'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXu-nXyrbaTo",
        "outputId": "2fbceb98-9f85-4d9a-999a-655efc343a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# add preprocessing layer to the front of VGG\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G1M8AUTbcnl"
      },
      "outputs": [],
      "source": [
        "# don't train existing weights\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXnS12XubgBB"
      },
      "outputs": [],
      "source": [
        " # useful for getting number of classes\n",
        "folders = glob('/content/drive/MyDrive/train_dir/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpoQ7MPXbkKq"
      },
      "outputs": [],
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YewKJ0XSbnfO"
      },
      "outputs": [],
      "source": [
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c37jR8FJbqrt",
        "outputId": "16d5dfea-a591-4856-bf1c-839d3d393a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 175623    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,890,311\n",
            "Trainable params: 175,623\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# view the structure of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmKOGVj8bv8w"
      },
      "outputs": [],
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl34lZYUby_P"
      },
      "outputs": [],
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255\n",
        "                                   )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqz8h1_NcN8c",
        "outputId": "b9c2a6bb-07e7-4672-a8dd-a46d136cbafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9077 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/train_dir',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drPEYCr3ceGp",
        "outputId": "e306cc2e-2581-4e2e-fe75-67d29bb7909d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 938 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/val_dir',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 64,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP8vtzf7cq4Y",
        "outputId": "d38809c6-71db-4775-c059-e366ef32f8d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "142/142 [==============================] - 5035s 35s/step - loss: 0.9609 - accuracy: 0.6824 - val_loss: 0.5486 - val_accuracy: 0.8252\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 149s 1s/step - loss: 0.7356 - accuracy: 0.7393 - val_loss: 0.5221 - val_accuracy: 0.8326\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 145s 1s/step - loss: 0.6507 - accuracy: 0.7705 - val_loss: 0.4993 - val_accuracy: 0.8465\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.5854 - accuracy: 0.7961 - val_loss: 0.4838 - val_accuracy: 0.8475\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.5464 - accuracy: 0.8103 - val_loss: 0.4850 - val_accuracy: 0.8507\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.5106 - accuracy: 0.8228 - val_loss: 0.4984 - val_accuracy: 0.8443\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.4680 - accuracy: 0.8378 - val_loss: 0.4703 - val_accuracy: 0.8550\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.4424 - accuracy: 0.8516 - val_loss: 0.4615 - val_accuracy: 0.8646\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.4066 - accuracy: 0.8626 - val_loss: 0.4635 - val_accuracy: 0.8646\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.3866 - accuracy: 0.8657 - val_loss: 0.4732 - val_accuracy: 0.8582\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.3751 - accuracy: 0.8753 - val_loss: 0.4798 - val_accuracy: 0.8561\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.3428 - accuracy: 0.8854 - val_loss: 0.4645 - val_accuracy: 0.8625\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 145s 1s/step - loss: 0.3459 - accuracy: 0.8841 - val_loss: 0.4813 - val_accuracy: 0.8582\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.3251 - accuracy: 0.8940 - val_loss: 0.4663 - val_accuracy: 0.8667\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.3075 - accuracy: 0.9027 - val_loss: 0.5138 - val_accuracy: 0.8571\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.3038 - accuracy: 0.8986 - val_loss: 0.4792 - val_accuracy: 0.8667\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 145s 1s/step - loss: 0.2853 - accuracy: 0.9098 - val_loss: 0.5218 - val_accuracy: 0.8603\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.2729 - accuracy: 0.9155 - val_loss: 0.4904 - val_accuracy: 0.8614\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 145s 1s/step - loss: 0.2626 - accuracy: 0.9154 - val_loss: 0.4854 - val_accuracy: 0.8667\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.2625 - accuracy: 0.9159 - val_loss: 0.5332 - val_accuracy: 0.8561\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.2457 - accuracy: 0.9221 - val_loss: 0.5014 - val_accuracy: 0.8731\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.2522 - accuracy: 0.9219 - val_loss: 0.5126 - val_accuracy: 0.8625\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 143s 1s/step - loss: 0.2237 - accuracy: 0.9333 - val_loss: 0.5058 - val_accuracy: 0.8625\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 143s 1s/step - loss: 0.2162 - accuracy: 0.9361 - val_loss: 0.5858 - val_accuracy: 0.8486\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.2184 - accuracy: 0.9326 - val_loss: 0.5216 - val_accuracy: 0.8657\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.2121 - accuracy: 0.9358 - val_loss: 0.5480 - val_accuracy: 0.8593\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1970 - accuracy: 0.9404 - val_loss: 0.5178 - val_accuracy: 0.8614\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 151s 1s/step - loss: 0.1905 - accuracy: 0.9432 - val_loss: 0.5298 - val_accuracy: 0.8710\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1984 - accuracy: 0.9376 - val_loss: 0.5840 - val_accuracy: 0.8614\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1841 - accuracy: 0.9456 - val_loss: 0.5377 - val_accuracy: 0.8625\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1719 - accuracy: 0.9493 - val_loss: 0.6078 - val_accuracy: 0.8593\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1872 - accuracy: 0.9405 - val_loss: 0.5602 - val_accuracy: 0.8561\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1696 - accuracy: 0.9504 - val_loss: 0.5931 - val_accuracy: 0.8603\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 145s 1s/step - loss: 0.1540 - accuracy: 0.9558 - val_loss: 0.5967 - val_accuracy: 0.8593\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 145s 1s/step - loss: 0.1558 - accuracy: 0.9558 - val_loss: 0.5688 - val_accuracy: 0.8635\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.1544 - accuracy: 0.9554 - val_loss: 0.6250 - val_accuracy: 0.8486\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.1538 - accuracy: 0.9545 - val_loss: 0.5996 - val_accuracy: 0.8646\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.1468 - accuracy: 0.9556 - val_loss: 0.5684 - val_accuracy: 0.8742\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.1303 - accuracy: 0.9657 - val_loss: 0.5748 - val_accuracy: 0.8689\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.1280 - accuracy: 0.9651 - val_loss: 0.5991 - val_accuracy: 0.8539\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.1433 - accuracy: 0.9592 - val_loss: 0.6522 - val_accuracy: 0.8571\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1272 - accuracy: 0.9649 - val_loss: 0.6152 - val_accuracy: 0.8667\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.1310 - accuracy: 0.9633 - val_loss: 0.6139 - val_accuracy: 0.8603\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 144s 1s/step - loss: 0.1280 - accuracy: 0.9653 - val_loss: 0.6078 - val_accuracy: 0.8689\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 147s 1s/step - loss: 0.1158 - accuracy: 0.9697 - val_loss: 0.6147 - val_accuracy: 0.8646\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 149s 1s/step - loss: 0.1088 - accuracy: 0.9734 - val_loss: 0.6479 - val_accuracy: 0.8603\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.1099 - accuracy: 0.9727 - val_loss: 0.6624 - val_accuracy: 0.8625\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.0997 - accuracy: 0.9752 - val_loss: 0.6341 - val_accuracy: 0.8742\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 146s 1s/step - loss: 0.1221 - accuracy: 0.9639 - val_loss: 0.6460 - val_accuracy: 0.8657\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 148s 1s/step - loss: 0.0998 - accuracy: 0.9763 - val_loss: 0.6508 - val_accuracy: 0.8593\n"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=50,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled13.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}